\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{matrix}

\begin{document}

\title{Hierarchical Binomials Using an Approximate Infinite Mixture of Betas}
\author{Jacob Carey}

\maketitle

\section{Introduction}

When we have binomial data from different (but related) sources, we often want to share information between them. However, differences between the sources causes a false reduction in variance to pool the data together, and modeling them separately loses information. In this instance, I was interested in the variance between the sources. A typical model choice is a \textit{Beta-Binomial model} written

\begin{equation}\label{betabinom}
\theta_i \sim \text{Beta}(\alpha, \beta)
\end{equation}

where the variance between the souces follows the definition of a Beta distribution with the approximated $\alpha, \beta$ parameters. However, the problem with \eqref{betabinom} is that we force the typically uni-modal assumption on the underylying distribution of the $\theta$'s. A natural extension is to use a \textit{mixture of Beta} distributions for the hierarchical distribution.

\begin{equation}\label{finitemix-betabinom}
\theta_i \sim \sum_i^K pi_i \times \text{Beta}(\alpha_k, \beta_k)
\end{equation}

\eqref{finitemix-betabinom} allows for a more flexible hierarchical distribution. However, we have now introduced a different problem - how do you decide on $K$?

\section{Methods}

A solution arrives from the field of \textbf{Nonparametric Bayesian Statistics}. Instead of \eqref{finitemix-betabinom}, a more relaxed choice is an \textit{infinite mixture model}

\begin{equation}\label{infinitemix-betabinom}
\theta_i \sim \sum_i^{\infty} pi_i \times \text{Beta}(\alpha_k, \beta_k)
\end{equation}

In practice, an infinite mixture like \eqref{infinitemix-beta} is implemented as a \textbf{Dirichlet Process Mixture}. Here, I have elected to use \eqref{finitemix-betabinom}, but with a large $K$.

\section{Discussion}

\end{document}
